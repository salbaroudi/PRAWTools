ID,User,DateCreated,Text
9b2npw;seekingtheta_shoes;1535518145.0;Let's talk about the underdog: TSMC
9b2npw;seekingtheta_shoes;1535518145.0;"TSMC has a monopoly on 7 nanometer from Apple (75% of 7nm orders), AMD (cpu, gpu?), NVDA (post-volta/turing), and now qualcomm (snapdragon). With growing demand from other sources besides mobile and the expectation that NAND/DRAM ASPs will cool, I think they will set their sights on increasing profit margins. Their margins have in the past been contracting due to capex for 5-nanometer and crypto headwinds. It has also been reported that TSMC has the highest yield/quality 7 nanometer node as compared to the rivals, Intel and Samsung. Intel's 10 nanometer (equivalent to ITRS 7 nanometer) is rumored to be delayed another year. Apple will continue to use TSMC as Intel doesn't have mobile nodes (low power and leakage), and Samsung already supplies a $ of BOM including OLED and memory to Apple. In the AI space, TSMC is fabricating Graphcore's giant AI accelerator, which replaces DRAM with on-chip SRAM. IN my mind, this is the strongest competitor of NVDA (apart from big tech building their own training chips). This is because AI perf depends strongly on the memory due to IO-bound nature of DL training. Conclusion: TSMC has a growing monopoly over mobile (virtually all non-Samsung phones), AI (NVDA, Google/FB/AAPL, and Graphcore). And now TSMC will enter the server market through AMD. In my semi pick, I am super bullish on TSMC and slightly bullish on AMD + NVDA. Short NAND makers. Regarding Intel, two uncertainties: 1) quality and yield of their 10-nm, and 2) release date of their 10-nm datacenter line. If TSMC increases die price to the customers, it puts Intel at an advantage. However, they will still lose server share... However, it is a good value semi company.https://en.wikichip.org/wiki/7_nm_lithography_process**Further technical musings:Notice anything strange by GF's cancellation in 7nm? They tried EUV (new technology with higher variation in silicon properties and systematic yield problems from wafer to wafer). Intel and Samsung are also using EUV, and I bet these delays are due to EUV. TSMC on the other hand is opting for more conventional 193 nm litho with proven consistent yields. However, in their 7nm++ LPP, they are pushing for EUV (https://www.eetimes.com/document.asp?doc_id=1333244)**   "

e4zwmp6;eskjcSFW;1535518772.0;"Look at tsm market cap. This is no underdog"
e4zy1p2;compounding;1535519997.0;"Counterpoint:They have a transient monopoly on 7nm. Samsung and GF are likely coming in early 2019, so that isn’t a durable advantage.Furthermore, most of their capacity for the rest of this year will be just keeping up with Apple and the word on the street is that “a primary customer” (i.e., Apple) fronted a large chunk of the cap-ex to accelerate the 7nm transition, so I would expect that 75% of those revenues to be at poverty level margins for a traditional beholden Apple supplier rather than “monopoly” margins you seem to expect.Yes, they have a very solid anchor-customer, and one that is extremely motivated to invest to make sure they stay at the head of the pack, but that same customer will demand most of their capacity during the time they have a technology edge and is notoriously brutal at cutting its supplier margins down to the bone.Also, last I heard, TSMC got the technology advantage by going with a process that was significantly more expensive to pattern and layout... Perfect for a massive cost-sensitive customer like Apple, but not ideal for their other customers with smaller scale who will need discounts to make up for added expenses in the design process. Samsung/GF are taking longer to come out with similar density, but once they do it will be more attractive to the non-Apple low-scale customers thanks to lower design expenses.TSMC is doing great, and huge props for being the first to knock Intel off their decades old throne! But its also a really hard business with a lot of nuance, and I feel your assumptions are far too optimistic even just from a cursory examination."
e5074lw;robertito42;1535528345.0;"Underdog?"
e504ls5;ObservationalHumor;1535525963.0;"TSMC is already serving most of the major customers out there.  Picking up AMD for 7nm has some upside but it's very possible they were close to demand constrained on that node anyways.I think there's two main potential problems, the first is that it's hard to imagine the semiconductor market getting any more favorable for TSMC at this point.  Intel is in disarray and they have just about every major high margin manufacturer on board.  Some of their older process nodes are going to be facing increasing competition from GF since they've abandoned 7nm for the time being too.> In the AI space, TSMC is fabricating Graphcore's giant AI accelerator, which replaces DRAM with on-chip SRAM. IN my mind, this is the strongest competitor of NVDA (apart from big tech building their own training chips). This is because AI perf depends strongly on the memory due to IO-bound nature of DL training. This sounds like horseshit to me.  SRAM is far less dense than DRAM and you're not going to be able to substitute it at a rate even close to 1 for 1.  Processors already have SRAM too and it's primary purpose is simply to hide DRAM latency.  Less overall memory than a DRAM based design is also going to increase demand on the I/O bus and worsen that problem rather than fix it.All that said I don't think TSMC is super expensive by any stretch it's a good stock to hold but it's tough to see where they're going to get significant additional growth from that isn't already being priced in at this point.> Further technical musings: Notice anything strange by GF's cancellation in 7nm? They tried EUV (new technology with higher variation in silicon properties and systematic yield problems from wafer to wafer). Intel and Samsung are also using EUV, and I bet these delays are due to EUV. TSMC on the other hand is opting for more conventional 193 nm litho with proven consistent yields. However, in their 7nm++ LPP, they are pushing for EUVIt's pretty clear this has been a tougher node than those in the past.  Intel struggling this badly is a sure sign on that given the significant lead they had going into this.  AMD's stock price has sky rocketed and we're back to seeing analysts asserting this is going to be a 5+ year shift Intel won't be able to come back from but I'm not confident that's actually the case.  We could very easily see things start shifting back in 2019 and 2020 if Intel gets it's process down and TSMC starts having difficulty with EUV and scaling beyond 7nm."
e4zxgst;seekingtheta_shoes;1535519503.0;"It's a huge company for sure but I think people are underestimating its performance. In their 2 last Qs, they guided down twice due to cryptocurrency headwinds (CEO: "We forecast TSMC's 2018 revenue in US dollar will be about 10%, rather than the previously indicated 10% to 15% due to the Smartphone weakness and the uncertainty in cryptocurrency mining demand.")"
e4zymtv;seekingtheta_shoes;1535520497.0;"Isn't GF done with 7nm? (https://www.extremetech.com/computing/276185-globalfoundries-radically-restructures-kills-7nm-spins-off-asic-design-team)TSMC's 7nm++ should be very competitive (EUV compared to 193nm light on 7nm) to Samsung 7nm around the same time as 7nm++ LPP offers 30% lower power than 7nm LPP. (https://www.eetimes.com/document.asp?doc_id=1333244)."
e4zzxk1;Project_Zero_Betas;1535521648.0;"Special occasion to break out this one?"
e50530a;seekingtheta_shoes;1535526409.0;"> This sounds like horseshit to me. SRAM is far less dense than DRAM and you're not going to be able to substitute it at a rate even close to 1 for 1. Processors already have SRAM too and it's primary purpose is simply to hide DRAM latency. Less overall memory than a DRAM based design is also going to increase demand on the I/O bus and worsen that problem rather than fix it.I understand that and until recently I held the same opinion. The idea is that DRAM doesn't scale as well as digital CMOS. So just looking at area efficiency, you get 6T (@<7nm) vs 1T (@20nm) which is not bad as compared with today's area efficiencies. Furthermore, you alleviate the IO constraints by stacking the silicon on top of one another (look at the graphcore paper) and using TSVs to achieve parallelism.Furthermore, this idea calls for much better energy efficiencies and faster latency. The idea is that you have architectures that have low fan-out fan-in such that you don't run into memory bottlenecks by large reductions or broadcasts. "
e505m4c;seekingtheta_shoes;1535526915.0;"also, keep in mind that the way we think about caching and persistence in memory hierarchies need revision for machine learning. The assumption that having DRAM as necessary need not be transferred from the bygone days of multi-core architectures."
e502qy8;compounding;1535524247.0;"Wow, that’s... interesting! I think that demonstrates how hard the business is, though GF was bound to have trouble finding the $20 B to have a competitive process. A bit surprised they are making the call so late (and suddenly!) though, weren’t they promising 4th quarter customer tape-outs as recently as last month?I think TSMC will continue to be very competitive technology-wise, Apple will make sure of it, they wouldn’t have bet on a single horse without being sure they can execute on their chip strategy which relies on getting the very best.My main concern for your TSMC thesis is the “deal with the Devil” in Apple, who will keep them ahead in technology but demand priority production at low(er) margins. But if the remaining lucrative business is now just split with Samsung, that does help quite a bit... especially because without two bi-directional (cheaper tape-outs) competitors, Samsung won’t be forced to compete for smaller customers and is less likely to drive down the price vs. just enjoying fat margins for themselves."
e50ciha;ObservationalHumor;1535533597.0;"> I understand that and until recently I held the same opinion. The idea is that DRAM doesn't scale as well as digital CMOS. So just looking at area efficiency, you get 6T (@<7nm) vs 1T (@20nm) which is not bad as compared with today's area efficienciesPer their own deck they were projecting total SRAM to be about 1/27th of what a DRAM setup would give you.> urthermore, you alleviate the IO constraints by stacking the silicon on top of one another (look at the graphcore paper) and using TSVs to achieve parallelism. Furthermore, this idea calls for much better energy efficiencies and faster latency. The idea is that you have architectures that have low fan-out fan-in such that you don't run into memory bottlenecks by large reductions or broadcasts.I get what the idea is, the point is that it still isn't removing the major bottleneck of actually feeding a discrete card data in the first place.  In fact it makes that problem even larger since exceeding the available on chip memory pretty much requires you shuffle things into system DRAM over the PCI bus.  You also can't just stack silicon forever, heat is the ultimate enemy here and you can only go so thick before dissipation becomes a critical problem.There's a big asterisk here on being able to significantly reduce memory footprints algorithmically.  Which may or may not be feasible for a bunch of applications.  The example they give is literally to recompute a large amount of the data instead of caching it and overall benefit is a 25% speedup in compute time.  I mean you're getting a speedup here but it's mostly useless because the processor is ultimately data starved and has to spin recomputing everything anyways.I get what they're trying to do but it's a lot of work for very little gain here unless you're specifically working with pretty small nets and data sets."
